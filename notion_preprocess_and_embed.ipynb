{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniconda3/ openai\n",
    "\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x106011300> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Alquier, 2021)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 159.076,\n",
       "      \"text\": \"(Alquier, 2021)\\nAbstract: Aggregated predictors are obtained by making a set of basic predictors vote according to some weights, that is, to some probability distribution. Randomized predictors are obtained by sampling in a set of basic predictors, according to some prescribed probability distribution. Thus, aggregated and randomized predictors have in common that they are not defined by a minimization problem, but by a probability distribution on the set of predictors. In statistical learning theory, there is a set of tools designed to understand the generalization ability of such procedures: PAC-Bayesian or PAC-Bayes bounds. Since the original PAC-Bayes bounds of D. McAllester, these tools have been considerably improved in many directions (we will for example describe a simplified version of the localization technique of O. Catoni that was missed by the community, and later rediscovered as \\\"mutual information bounds\\\"). Very recently, PAC-Bayes bounds received a considerable attention: for example there was workshop on PAC-Bayes at NIPS 2017, \\\"(Almost) 50 Shades of Bayesian Learning: PAC-Bayesian trends and insights\\\", organized by B. Guedj, F. Bach and P. Germain. One of the reason of this recent success is the successful application of these bounds to neural networks by G. Dziugaite and D. Roy. An elementary introduction to PAC-Bayes theory is still missing. This is an attempt to provide such an introduction.\\nAuthors: Alquier, Pierre\\nFile Path: /Users/kastanday/Zotero/storage/BB4BXE5A/Alquier_2021_User-friendly introduction to PAC-Bayes bounds.pdf\\nFull Citation: Alquier, Pierre. \\u201cUser-Friendly Introduction to PAC-Bayes Bounds.\\u201d ArXiv:2110.11216 [Cs, Math, Stat], October 28, 2021. http://arxiv.org/abs/2110.11216.\\nIn-Text Citation: (Alquier, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, test-tag-notion, \\u26d4 No DOI found\\nTitle: User-friendly introduction to PAC-Bayes bounds\\nURL: http://arxiv.org/abs/2110.11216\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/LEVPDTUR\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Lopez-Paz et al., 2017)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 92.792,\n",
       "      \"text\": \"(Lopez-Paz et al., 2017)\\nAbstract: This paper establishes the existence of observable footprints that reveal the \\\"causal dispositions\\\" of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.\\nAuthors: Lopez-Paz, David\\nNishihara, Robert\\nChintala, Soumith\\nSch\\u00f6lkopf, Bernhard\\nBottou, L\\u00e9on\\nFile Path: /Users/kastanday/Zotero/storage/EMWPNSPM/Lopez-Paz et al. - 2017 - Discovering Causal Signals in Images.pdf\\nFull Citation: Lopez-Paz, David, Robert Nishihara, Soumith Chintala, Bernhard Sch\\u00f6lkopf, and L\\u00e9on Bottou. \\u201cDiscovering Causal Signals in Images.\\u201d ArXiv:1605.08179 [Cs, Stat], October 31, 2017. http://arxiv.org/abs/1605.08179.\\nIn-Text Citation: (Lopez-Paz et al., 2017)\\nItem Type: Journal Article\\nTags: Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, attention, test-tag-notion, \\u26d4 No DOI found\\nTitle: Discovering Causal Signals in Images\\nURL: http://arxiv.org/abs/1605.08179\\nYear: 2017\\nZotero URI: http://zotero.org/users/3570394/items/M68BUSYI\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Kirsch & Schmidhuber, 2021)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 122.546,\n",
       "      \"text\": \"(Kirsch & Schmidhuber, 2021)\\nAbstract: Many concepts have been proposed for meta learning with neural networks (NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity, learned learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning (VSML) unifies the above and demonstrates that simple weight-sharing and sparsity in an NN is sufficient to express powerful learning algorithms (LAs) in a reusable fashion. A simple implementation of VSML where the weights of a neural network are replaced by tiny LSTMs allows for implementing the backpropagation LA solely by running in forward-mode. It can even meta learn new LAs that differ from online backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. Introspection reveals that our meta learned LAs learn through fast association in a way that is qualitatively different from gradient descent.\\nAuthors: Kirsch, Louis\\nSchmidhuber, J\\u00fcrgen\\nFile Path: /Users/kastanday/Zotero/storage/6FLHJNPR/Kirsch and Schmidhuber - 2021 - Meta Learning Backpropagation And Improving It.pdf\\nFull Citation: Kirsch, Louis, and J\\u00fcrgen Schmidhuber. \\u201cMeta Learning Backpropagation And Improving It.\\u201d ArXiv:2012.14905 [Cs, Stat], October 29, 2021. http://arxiv.org/abs/2012.14905.\\nIn-Text Citation: (Kirsch & Schmidhuber, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, metalearning, test-tag-notion, \\u26d4 No DOI found\\nTitle: Meta Learning Backpropagation And Improving It\\nURL: http://arxiv.org/abs/2012.14905\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/K68G4SRC\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = openai.Engine(\"ada\").search(\n",
    "#     search_model=\"ada\", \n",
    "#     query=\"discrete stat distribution\", \n",
    "#     max_rerank=3,\n",
    "#     file=\"file-NdM8EkdPCKFmEcL9ksaKR27K\",\n",
    "#     return_metadata=True\n",
    "# )\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: (Alquier, 2021)\n",
      "\n",
      "(Alquier, 2021)\n",
      "Abstract: Aggregated predictors are obtained by making a set of basic predictors vote according to some weights, that is, to some probability distribution. Randomized predictors are obtained by sampling in a set of basic predictors, according to some prescribed probability distribution. Thus, aggregated and randomized predictors have in common that they are not defined by a minimization problem, but by a probability distribution on the set of predictors. In statistical learning theory, there is a set of tools designed to understand the generalization ability of such procedures: PAC-Bayesian or PAC-Bayes bounds. Since the original PAC-Bayes bounds of D. McAllester, these tools have been considerably improved in many directions (we will for example describe a simplified version of the localization technique of O. Catoni that was missed by the community, and later rediscovered as \"mutual information bounds\"). Very recently, PAC-Bayes bounds received a considerable attention: for example there was workshop on PAC-Bayes at NIPS 2017, \"(Almost) 50 Shades of Bayesian Learning: PAC-Bayesian trends and insights\", organized by B. Guedj, F. Bach and P. Germain. One of the reason of this recent success is the successful application of these bounds to neural networks by G. Dziugaite and D. Roy. An elementary introduction to PAC-Bayes theory is still missing. This is an attempt to provide such an introduction.\n",
      "Authors: Alquier, Pierre\n",
      "File Path: /Users/kastanday/Zotero/storage/BB4BXE5A/Alquier_2021_User-friendly introduction to PAC-Bayes bounds.pdf\n",
      "Full Citation: Alquier, Pierre. “User-Friendly Introduction to PAC-Bayes Bounds.” ArXiv:2110.11216 [Cs, Math, Stat], October 28, 2021. http://arxiv.org/abs/2110.11216.\n",
      "In-Text Citation: (Alquier, 2021)\n",
      "Item Type: Journal Article\n",
      "Tags: Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, test-tag-notion, ⛔ No DOI found\n",
      "Title: User-friendly introduction to PAC-Bayes bounds\n",
      "URL: http://arxiv.org/abs/2110.11216\n",
      "Year: 2021\n",
      "Zotero URI: http://zotero.org/users/3570394/items/LEVPDTUR\n",
      "\n",
      "Title: (Lopez-Paz et al., 2017)\n",
      "\n",
      "(Lopez-Paz et al., 2017)\n",
      "Abstract: This paper establishes the existence of observable footprints that reveal the \"causal dispositions\" of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.\n",
      "Authors: Lopez-Paz, David\n",
      "Nishihara, Robert\n",
      "Chintala, Soumith\n",
      "Schölkopf, Bernhard\n",
      "Bottou, Léon\n",
      "File Path: /Users/kastanday/Zotero/storage/EMWPNSPM/Lopez-Paz et al. - 2017 - Discovering Causal Signals in Images.pdf\n",
      "Full Citation: Lopez-Paz, David, Robert Nishihara, Soumith Chintala, Bernhard Schölkopf, and Léon Bottou. “Discovering Causal Signals in Images.” ArXiv:1605.08179 [Cs, Stat], October 31, 2017. http://arxiv.org/abs/1605.08179.\n",
      "In-Text Citation: (Lopez-Paz et al., 2017)\n",
      "Item Type: Journal Article\n",
      "Tags: Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, attention, test-tag-notion, ⛔ No DOI found\n",
      "Title: Discovering Causal Signals in Images\n",
      "URL: http://arxiv.org/abs/1605.08179\n",
      "Year: 2017\n",
      "Zotero URI: http://zotero.org/users/3570394/items/M68BUSYI\n",
      "\n",
      "Title: (Kirsch & Schmidhuber, 2021)\n",
      "\n",
      "(Kirsch & Schmidhuber, 2021)\n",
      "Abstract: Many concepts have been proposed for meta learning with neural networks (NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity, learned learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning (VSML) unifies the above and demonstrates that simple weight-sharing and sparsity in an NN is sufficient to express powerful learning algorithms (LAs) in a reusable fashion. A simple implementation of VSML where the weights of a neural network are replaced by tiny LSTMs allows for implementing the backpropagation LA solely by running in forward-mode. It can even meta learn new LAs that differ from online backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. Introspection reveals that our meta learned LAs learn through fast association in a way that is qualitatively different from gradient descent.\n",
      "Authors: Kirsch, Louis\n",
      "Schmidhuber, Jürgen\n",
      "File Path: /Users/kastanday/Zotero/storage/6FLHJNPR/Kirsch and Schmidhuber - 2021 - Meta Learning Backpropagation And Improving It.pdf\n",
      "Full Citation: Kirsch, Louis, and Jürgen Schmidhuber. “Meta Learning Backpropagation And Improving It.” ArXiv:2012.14905 [Cs, Stat], October 29, 2021. http://arxiv.org/abs/2012.14905.\n",
      "In-Text Citation: (Kirsch & Schmidhuber, 2021)\n",
      "Item Type: Journal Article\n",
      "Tags: Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, metalearning, test-tag-notion, ⛔ No DOI found\n",
      "Title: Meta Learning Backpropagation And Improving It\n",
      "URL: http://arxiv.org/abs/2012.14905\n",
      "Year: 2021\n",
      "Zotero URI: http://zotero.org/users/3570394/items/K68G4SRC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in response['data']:\n",
    "\n",
    "    print('Title: {}\\n{}\\n'.format(document['metadata']['title'], document['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'object': 'search_result',\n",
       "   'document': 0,\n",
       "   'score': 158.83,\n",
       "   'text': '(Alquier, 2021)\\nAbstract: Aggregated predictors are obtained by making a set of basic predictors vote according to some weights, that is, to some probability distribution. Randomized predictors are obtained by sampling in a set of basic predictors, according to some prescribed probability distribution. Thus, aggregated and randomized predictors have in common that they are not defined by a minimization problem, but by a probability distribution on the set of predictors. In statistical learning theory, there is a set of tools designed to understand the generalization ability of such procedures: PAC-Bayesian or PAC-Bayes bounds. Since the original PAC-Bayes bounds of D. McAllester, these tools have been considerably improved in many directions (we will for example describe a simplified version of the localization technique of O. Catoni that was missed by the community, and later rediscovered as \"mutual information bounds\"). Very recently, PAC-Bayes bounds received a considerable attention: for example there was workshop on PAC-Bayes at NIPS 2017, \"(Almost) 50 Shades of Bayesian Learning: PAC-Bayesian trends and insights\", organized by B. Guedj, F. Bach and P. Germain. One of the reason of this recent success is the successful application of these bounds to neural networks by G. Dziugaite and D. Roy. An elementary introduction to PAC-Bayes theory is still missing. This is an attempt to provide such an introduction.\\nAuthors: Alquier, Pierre\\nFile Path: /Users/kastanday/Zotero/storage/BB4BXE5A/Alquier_2021_User-friendly introduction to PAC-Bayes bounds.pdf\\nFull Citation: Alquier, Pierre. “User-Friendly Introduction to PAC-Bayes Bounds.” ArXiv:2110.11216 [Cs, Math, Stat], October 28, 2021. http://arxiv.org/abs/2110.11216.\\nIn-Text Citation: (Alquier, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, test-tag-notion, ⛔ No DOI found\\nTitle: User-friendly introduction to PAC-Bayes bounds\\nURL: http://arxiv.org/abs/2110.11216\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/LEVPDTUR',\n",
       "   'metadata': {'date_created': None,\n",
       "    'date_modified': None,\n",
       "    'title': '(Alquier, 2021)\\n'}},\n",
       "  {'object': 'search_result',\n",
       "   'document': 1,\n",
       "   'score': 92.792,\n",
       "   'text': '(Lopez-Paz et al., 2017)\\nAbstract: This paper establishes the existence of observable footprints that reveal the \"causal dispositions\" of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.\\nAuthors: Lopez-Paz, David\\nNishihara, Robert\\nChintala, Soumith\\nSchölkopf, Bernhard\\nBottou, Léon\\nFile Path: /Users/kastanday/Zotero/storage/EMWPNSPM/Lopez-Paz et al. - 2017 - Discovering Causal Signals in Images.pdf\\nFull Citation: Lopez-Paz, David, Robert Nishihara, Soumith Chintala, Bernhard Schölkopf, and Léon Bottou. “Discovering Causal Signals in Images.” ArXiv:1605.08179 [Cs, Stat], October 31, 2017. http://arxiv.org/abs/1605.08179.\\nIn-Text Citation: (Lopez-Paz et al., 2017)\\nItem Type: Journal Article\\nTags: Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, attention, test-tag-notion, ⛔ No DOI found\\nTitle: Discovering Causal Signals in Images\\nURL: http://arxiv.org/abs/1605.08179\\nYear: 2017\\nZotero URI: http://zotero.org/users/3570394/items/M68BUSYI',\n",
       "   'metadata': {'date_created': None,\n",
       "    'date_modified': None,\n",
       "    'title': '(Lopez-Paz et al., 2017)\\n'}},\n",
       "  {'object': 'search_result',\n",
       "   'document': 2,\n",
       "   'score': 120.911,\n",
       "   'text': '(Kirsch & Schmidhuber, 2021)\\nAbstract: Many concepts have been proposed for meta learning with neural networks (NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity, learned learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning (VSML) unifies the above and demonstrates that simple weight-sharing and sparsity in an NN is sufficient to express powerful learning algorithms (LAs) in a reusable fashion. A simple implementation of VSML where the weights of a neural network are replaced by tiny LSTMs allows for implementing the backpropagation LA solely by running in forward-mode. It can even meta learn new LAs that differ from online backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. Introspection reveals that our meta learned LAs learn through fast association in a way that is qualitatively different from gradient descent.\\nAuthors: Kirsch, Louis\\nSchmidhuber, Jürgen\\nFile Path: /Users/kastanday/Zotero/storage/6FLHJNPR/Kirsch and Schmidhuber - 2021 - Meta Learning Backpropagation And Improving It.pdf\\nFull Citation: Kirsch, Louis, and Jürgen Schmidhuber. “Meta Learning Backpropagation And Improving It.” ArXiv:2012.14905 [Cs, Stat], October 29, 2021. http://arxiv.org/abs/2012.14905.\\nIn-Text Citation: (Kirsch & Schmidhuber, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, metalearning, test-tag-notion, ⛔ No DOI found\\nTitle: Meta Learning Backpropagation And Improving It\\nURL: http://arxiv.org/abs/2012.14905\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/K68G4SRC',\n",
       "   'metadata': {'date_created': None,\n",
       "    'date_modified': None,\n",
       "    'title': '(Kirsch & Schmidhuber, 2021)\\n'}}],\n",
       " 'model': 'ada:2020-05-03'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "hi = json.load(open(\"one_search_response.json\"))\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x106ffffb0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-code-search-code\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-code-search-text\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-search-document\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-search-query\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada-similarity\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-code-search-code\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-code-search-text\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-search-document\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-search-query\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage-similarity\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-davinci-edit-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-instruct-beta-v2\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-search-document\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-search-query\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-similarity\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-instruct-beta-v3\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-search-document\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-search-query\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-similarity\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-edit-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-insert-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-davinci-insert-002\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"replicas\": null\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = None #YOUR API KEY HERE\n",
    "openai.Engine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found files: 1056\n"
     ]
    }
   ],
   "source": [
    "# glob all md files in current directory into list of files\n",
    "from pathlib import Path\n",
    "# current working directory\n",
    "# Path()\n",
    "notion_export_path = Path.cwd() / r'Notion-exports'\n",
    "mdfiles = list(notion_export_path.glob(\"**/*.md\"))\n",
    "print(\"found files:\", len(mdfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# limits\n",
    "https://beta.openai.com/docs/api-reference/searches\n",
    "\n",
    "200 docs max per upload\n",
    "docs cant be too long... \n",
    "The maximum document length (in tokens) is 2034 minus the number of tokens in the query.\n",
    "\n",
    "\n",
    "\n",
    "The similarity score is a positive score that usually ranges from 0 to 300 (but can sometimes go higher), where a score above 200 usually means the document is semantically similar to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Readwise\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Readwise\\n[Daily Reviews](Readwise%20db63a/Dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curiosity\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Curiosity\\n[Curiosity Notes](Curiosity%200990c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>People\\n[People database](People%20278e2/Peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Things to Blog About\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Things to Blog About\\n[Revamping my blog](Thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cuts from Designing Better Books\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Cuts from Designing Better Books\\nCuts from De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>(Eykholt_Robust_Physical-World_Attacks_CVPR_20...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Eykholt_Robust_Physical-World_Attacks_CVPR_20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>(Dean et al., n.d.)\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Dean et al., n.d.)\\nAbstract: We consider thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>(Sławek &amp; Arodź, 2013)\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Sławek &amp; Arodź, 2013)\\nAbstract: Background: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>(Dibaeinia &amp; Sinha, 2020)\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Dibaeinia &amp; Sinha, 2020)\\nAbstract: A common ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>(Ahmad &amp; Hawkins, 2016)\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Ahmad &amp; Hawkins, 2016)\\nAbstract: We propose ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title date_created  \\\n",
       "0                                            Readwise\\n                \n",
       "1                                           Curiosity\\n                \n",
       "2                                              People\\n                \n",
       "3                                Things to Blog About\\n                \n",
       "4                    Cuts from Designing Better Books\\n                \n",
       "...                                                 ...          ...   \n",
       "1051  (Eykholt_Robust_Physical-World_Attacks_CVPR_20...                \n",
       "1052                              (Dean et al., n.d.)\\n                \n",
       "1053                           (Sławek & Arodź, 2013)\\n                \n",
       "1054                        (Dibaeinia & Sinha, 2020)\\n                \n",
       "1055                          (Ahmad & Hawkins, 2016)\\n                \n",
       "\n",
       "     date_modified                                               text  \n",
       "0                   Readwise\\n[Daily Reviews](Readwise%20db63a/Dai...  \n",
       "1                   Curiosity\\n[Curiosity Notes](Curiosity%200990c...  \n",
       "2                   People\\n[People database](People%20278e2/Peopl...  \n",
       "3                   Things to Blog About\\n[Revamping my blog](Thin...  \n",
       "4                   Cuts from Designing Better Books\\nCuts from De...  \n",
       "...            ...                                                ...  \n",
       "1051                (Eykholt_Robust_Physical-World_Attacks_CVPR_20...  \n",
       "1052                (Dean et al., n.d.)\\nAbstract: We consider thr...  \n",
       "1053                (Sławek & Arodź, 2013)\\nAbstract: Background: ...  \n",
       "1054                (Dibaeinia & Sinha, 2020)\\nAbstract: A common ...  \n",
       "1055                (Ahmad & Hawkins, 2016)\\nAbstract: We propose ...  \n",
       "\n",
       "[1056 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEAN NOTION NOTION DATABASE EXPORT (from right click, export as csv) \n",
    "\n",
    "data = []\n",
    "\n",
    "for filepath in mdfiles:\n",
    "    file = open(filepath, 'r')\n",
    "    text = \"\"\n",
    "    date_created = \"\"\n",
    "    date_modified = \"\"\n",
    "    for idx, line in enumerate(file.readlines()):\n",
    "        if idx == 0:\n",
    "            line = line.strip(\"# \")\n",
    "            title = line\n",
    "            # keep title in body\n",
    "            # continue \n",
    "        while line.startswith(' '):\n",
    "            line = line[1:]\n",
    "        if line.startswith('Date Created:'):\n",
    "            line = line[14:] # remove first 14 chars.\n",
    "            date_created = line\n",
    "            continue\n",
    "        if line.startswith('Date Modified:'):\n",
    "            line = line[15:] # remove first 15 chars for \"Date Modified: \"\n",
    "            date_modified = line\n",
    "            continue\n",
    "        if line.startswith('[http'): \n",
    "            # Keeps links that have an alias!! Yay. Should remove link http part... and clean formatting\n",
    "            # todo, keep just the [] part and not the () part in \"[text](link)\"\n",
    "            continue\n",
    "        if not line.startswith('!') and len(line) >= 3:\n",
    "            text = text + str(line)\n",
    "            \n",
    "    # DANGER: limit each doc size!\n",
    "    # also, only 200 doc limit. RN I have 135 docs.\n",
    "    text = text[0:2500]\n",
    "    data.append([title,date_created,date_modified, text])\n",
    "    # print(text) \n",
    "    # break\n",
    "    \n",
    "df = pd.DataFrame(data=data)\n",
    "df.columns = [\"title\",\"date_created\",\"date_modified\", \"text\"]\n",
    "# save dataframe df as csv file\n",
    "df.to_csv(\"firsttry_all_base_notes.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plastics\\n</td>\n",
       "      <td>March 23, 2021 1:33 PM\\n</td>\n",
       "      <td>March 23, 2021 1:42 PM\\n</td>\n",
       "      <td>Plastics\\n1 and 2 do get recycled. 7 is catch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Networking HTTP/3\\n</td>\n",
       "      <td>January 7, 2022 7:42 PM\\n</td>\n",
       "      <td>January 7, 2022 8:19 PM\\n</td>\n",
       "      <td>Networking HTTP/3\\nHTTPS = TCP + TLS + HTTP\\n-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Date ideas\\n</td>\n",
       "      <td>December 22, 2020 3:28 PM\\n</td>\n",
       "      <td>May 22, 2021 5:18 PM\\n</td>\n",
       "      <td>Date ideas\\nMuseums are looking nice \\nthat ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>energy to the moon\\n</td>\n",
       "      <td>March 7, 2021 4:53 PM\\n</td>\n",
       "      <td>March 7, 2021 4:59 PM\\n</td>\n",
       "      <td>energy to the moon\\nname: energy —- in the props</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engineering for change\\n</td>\n",
       "      <td>December 2, 2020 7:54 PM\\n</td>\n",
       "      <td>March 14, 2021 4:46 PM\\n</td>\n",
       "      <td>engineering for change\\n# Sannitation\\n[Sanita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Second Call for Proposals Digital Transformati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Second Call for Proposals Digital Transformati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Quantum Fourier Transform\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quantum Fourier Transform\\n[Untitled](Quantum%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Quantum Eraser (Delayed Choice)\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quantum Eraser (Delayed Choice)\\nCreated: Octo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>When it comes down to it, the most obvious app...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When it comes down to it, the most obvious app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>While an isolated qubit's state will generally...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While an isolated qubit's state will generally...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                                           Plastics\\n   \n",
       "1                                  Networking HTTP/3\\n   \n",
       "2                                         Date ideas\\n   \n",
       "3                                 energy to the moon\\n   \n",
       "4                             engineering for change\\n   \n",
       "..                                                 ...   \n",
       "130  Second Call for Proposals Digital Transformati...   \n",
       "131                        Quantum Fourier Transform\\n   \n",
       "132                  Quantum Eraser (Delayed Choice)\\n   \n",
       "133  When it comes down to it, the most obvious app...   \n",
       "134  While an isolated qubit's state will generally...   \n",
       "\n",
       "                    date_created              date_modified  \\\n",
       "0       March 23, 2021 1:33 PM\\n   March 23, 2021 1:42 PM\\n   \n",
       "1      January 7, 2022 7:42 PM\\n  January 7, 2022 8:19 PM\\n   \n",
       "2    December 22, 2020 3:28 PM\\n     May 22, 2021 5:18 PM\\n   \n",
       "3        March 7, 2021 4:53 PM\\n    March 7, 2021 4:59 PM\\n   \n",
       "4     December 2, 2020 7:54 PM\\n   March 14, 2021 4:46 PM\\n   \n",
       "..                           ...                        ...   \n",
       "130                          NaN                        NaN   \n",
       "131                          NaN                        NaN   \n",
       "132                          NaN                        NaN   \n",
       "133                          NaN                        NaN   \n",
       "134                          NaN                        NaN   \n",
       "\n",
       "                                                  text  \n",
       "0    Plastics\\n1 and 2 do get recycled. 7 is catch ...  \n",
       "1    Networking HTTP/3\\nHTTPS = TCP + TLS + HTTP\\n-...  \n",
       "2    Date ideas\\nMuseums are looking nice \\nthat ne...  \n",
       "3     energy to the moon\\nname: energy —- in the props  \n",
       "4    engineering for change\\n# Sannitation\\n[Sanita...  \n",
       "..                                                 ...  \n",
       "130  Second Call for Proposals Digital Transformati...  \n",
       "131  Quantum Fourier Transform\\n[Untitled](Quantum%...  \n",
       "132  Quantum Eraser (Delayed Choice)\\nCreated: Octo...  \n",
       "133  When it comes down to it, the most obvious app...  \n",
       "134  While an isolated qubit's state will generally...  \n",
       "\n",
       "[135 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas load csv to dataframe\n",
    "notes = pd.read_csv(\"curiosity_notes_clean.csv\")#,header=None)\n",
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.File.create(file=open(\"myfile.jsonl\"), purpose=\"search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"text\": \"text of file\"}\n",
    "\n",
    "# filename = 'alltext.jsonl'\n",
    "\n",
    "# for line in notes.text:\n",
    "#     print(line)\n",
    "#     out = \n",
    "#     out = f\"\\{\\\"text\\\"\\}:\\\"{line}\\\"\"\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224924"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find total words\n",
    "notes = pd.read_csv(\"firsttry_all_base_notes.csv\")#,header=None)\n",
    "alltext = notes.text.sum()\n",
    "\n",
    "res = len(alltext.split())\n",
    "res \n",
    "\n",
    "# 16_613 words for curiosity notes database\n",
    "# 224_924 words for all base directory notes (counting space-delimited words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Jsonl for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode csv into jsonl format for Openai File upload\n",
    "\n",
    "notes = pd.read_csv(\"firsttry_all_base_notes.csv\")#,header=None)\n",
    "\n",
    "# create metatdata formated for Openai\n",
    "notes['metadata'] = notes.apply(lambda row: {'date_created':row['date_created'], 'date_modified':row['date_modified'], 'title': row['title']}, axis=1)\n",
    "\n",
    "notes.drop([\"date_created\", \"date_modified\", \"title\"], axis=1, inplace=True)\n",
    "\n",
    "# notes.to_json(orient='records', lines=True)\n",
    "# notes['merged']\n",
    "\n",
    "# export to file\n",
    "notes.to_json(\"allBaseNots_withMetadata.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-NdM8EkdPCKFmEcL9ksaKR27K at 0x11e79cdb0> JSON: {\n",
       "  \"bytes\": 1794603,\n",
       "  \"created_at\": 1649561114,\n",
       "  \"filename\": \"allBaseNots_withMetadata.jsonl\",\n",
       "  \"id\": \"file-NdM8EkdPCKFmEcL9ksaKR27K\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"search\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(file=open(\"allBaseNots_withMetadata.jsonl\"), purpose=\"search\")\n",
    "\n",
    "# <File file id=file-YvfHj7utJala3er24T0ZqeLb at 0x15eccf3d0> JSON: {\n",
    "#   \"bytes\": 137010,\n",
    "#   \"created_at\": 1649388503,\n",
    "#   \"filename\": \"curiosityNotes.jsonl\",\n",
    "#   \"id\": \"file-YvfHj7utJala3er24T0ZqeLb\",\n",
    "#   \"object\": \"file\",\n",
    "#   \"purpose\": \"search\",\n",
    "#   \"status\": \"uploaded\",\n",
    "#   \"status_details\": null\n",
    "# }\n",
    "# file-YvfHj7utJala3er24T0ZqeLb  # before metadata\n",
    "# file-8wiFt4uSxNPRpaEwsCG0s6qD  # after including metadata\n",
    "# file-NdM8EkdPCKFmEcL9ksaKR27K allBaseNots_withMetadata.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x1283d75b0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Alquier, 2021)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 159.076,\n",
       "      \"text\": \"(Alquier, 2021)\\nAbstract: Aggregated predictors are obtained by making a set of basic predictors vote according to some weights, that is, to some probability distribution. Randomized predictors are obtained by sampling in a set of basic predictors, according to some prescribed probability distribution. Thus, aggregated and randomized predictors have in common that they are not defined by a minimization problem, but by a probability distribution on the set of predictors. In statistical learning theory, there is a set of tools designed to understand the generalization ability of such procedures: PAC-Bayesian or PAC-Bayes bounds. Since the original PAC-Bayes bounds of D. McAllester, these tools have been considerably improved in many directions (we will for example describe a simplified version of the localization technique of O. Catoni that was missed by the community, and later rediscovered as \\\"mutual information bounds\\\"). Very recently, PAC-Bayes bounds received a considerable attention: for example there was workshop on PAC-Bayes at NIPS 2017, \\\"(Almost) 50 Shades of Bayesian Learning: PAC-Bayesian trends and insights\\\", organized by B. Guedj, F. Bach and P. Germain. One of the reason of this recent success is the successful application of these bounds to neural networks by G. Dziugaite and D. Roy. An elementary introduction to PAC-Bayes theory is still missing. This is an attempt to provide such an introduction.\\nAuthors: Alquier, Pierre\\nFile Path: /Users/kastanday/Zotero/storage/BB4BXE5A/Alquier_2021_User-friendly introduction to PAC-Bayes bounds.pdf\\nFull Citation: Alquier, Pierre. \\u201cUser-Friendly Introduction to PAC-Bayes Bounds.\\u201d ArXiv:2110.11216 [Cs, Math, Stat], October 28, 2021. http://arxiv.org/abs/2110.11216.\\nIn-Text Citation: (Alquier, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, test-tag-notion, \\u26d4 No DOI found\\nTitle: User-friendly introduction to PAC-Bayes bounds\\nURL: http://arxiv.org/abs/2110.11216\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/LEVPDTUR\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Lopez-Paz et al., 2017)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 92.873,\n",
       "      \"text\": \"(Lopez-Paz et al., 2017)\\nAbstract: This paper establishes the existence of observable footprints that reveal the \\\"causal dispositions\\\" of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.\\nAuthors: Lopez-Paz, David\\nNishihara, Robert\\nChintala, Soumith\\nSch\\u00f6lkopf, Bernhard\\nBottou, L\\u00e9on\\nFile Path: /Users/kastanday/Zotero/storage/EMWPNSPM/Lopez-Paz et al. - 2017 - Discovering Causal Signals in Images.pdf\\nFull Citation: Lopez-Paz, David, Robert Nishihara, Soumith Chintala, Bernhard Sch\\u00f6lkopf, and L\\u00e9on Bottou. \\u201cDiscovering Causal Signals in Images.\\u201d ArXiv:1605.08179 [Cs, Stat], October 31, 2017. http://arxiv.org/abs/1605.08179.\\nIn-Text Citation: (Lopez-Paz et al., 2017)\\nItem Type: Journal Article\\nTags: Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, attention, test-tag-notion, \\u26d4 No DOI found\\nTitle: Discovering Causal Signals in Images\\nURL: http://arxiv.org/abs/1605.08179\\nYear: 2017\\nZotero URI: http://zotero.org/users/3570394/items/M68BUSYI\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Kirsch & Schmidhuber, 2021)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 123.226,\n",
       "      \"text\": \"(Kirsch & Schmidhuber, 2021)\\nAbstract: Many concepts have been proposed for meta learning with neural networks (NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity, learned learning rules, and meta recurrent NNs. Our Variable Shared Meta Learning (VSML) unifies the above and demonstrates that simple weight-sharing and sparsity in an NN is sufficient to express powerful learning algorithms (LAs) in a reusable fashion. A simple implementation of VSML where the weights of a neural network are replaced by tiny LSTMs allows for implementing the backpropagation LA solely by running in forward-mode. It can even meta learn new LAs that differ from online backpropagation and generalize to datasets outside of the meta training distribution without explicit gradient calculation. Introspection reveals that our meta learned LAs learn through fast association in a way that is qualitatively different from gradient descent.\\nAuthors: Kirsch, Louis\\nSchmidhuber, J\\u00fcrgen\\nFile Path: /Users/kastanday/Zotero/storage/6FLHJNPR/Kirsch and Schmidhuber - 2021 - Meta Learning Backpropagation And Improving It.pdf\\nFull Citation: Kirsch, Louis, and J\\u00fcrgen Schmidhuber. \\u201cMeta Learning Backpropagation And Improving It.\\u201d ArXiv:2012.14905 [Cs, Stat], October 29, 2021. http://arxiv.org/abs/2012.14905.\\nIn-Text Citation: (Kirsch & Schmidhuber, 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, metalearning, test-tag-notion, \\u26d4 No DOI found\\nTitle: Meta Learning Backpropagation And Improving It\\nURL: http://arxiv.org/abs/2012.14905\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/K68G4SRC\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Ba et al., 2016)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 172.841,\n",
       "      \"text\": \"(Ba et al., 2016)\\nAbstract: Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.\\nAuthors: Ba, Jimmy Lei\\nKiros, Jamie Ryan\\nHinton, Geoffrey E.\\nFile Path: /Users/kastanday/Zotero/storage/GJDWXZLR/Ba et al. - 2016 - Layer Normalization.pdf\\nFull Citation: Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \\u201cLayer Normalization.\\u201d ArXiv:1607.06450 [Cs, Stat], July 21, 2016. http://arxiv.org/abs/1607.06450.\\nIn-Text Citation: (Ba et al., 2016)\\nItem Type: Journal Article\\nTags: Computer Science - Machine Learning, Statistics - Machine Learning, test-tag-notion, \\u26d4 No DOI found\\nTitle: Layer Normalization\\nURL: http://arxiv.org/abs/1607.06450\\nYear: 2016\\nZotero URI: http://zotero.org/users/3570394/items/EMHVMTYF\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Liu et al., 2021)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 141.271,\n",
       "      \"text\": \"(Liu et al., 2021)\\nAbstract: Determining whether inputs are out-of-distribution (OOD) is an essential building block for safely deploying machine learning models in the open world. However, previous methods relying on the softmax confidence score suffer from overconfident posterior distributions for OOD data. We propose a unified framework for OOD detection that uses an energy score. We show that energy scores better distinguish in- and out-of-distribution samples than the traditional approach using the softmax scores. Unlike softmax confidence scores, energy scores are theoretically aligned with the probability density of the inputs and are less susceptible to the overconfidence issue. Within this framework, energy can be flexibly used as a scoring function for any pre-trained neural classifier as well as a trainable cost function to shape the energy surface explicitly for OOD detection. On a CIFAR-10 pre-trained WideResNet, using the energy score reduces the average FPR (at TPR 95%) by 18.03% compared to the softmax confidence score. With energy-based training, our method outperforms the state-of-the-art on common benchmarks.\\nAuthors: Liu, Weitang\\nWang, Xiaoyun\\nOwens, John D.\\nLi, Yixuan\\nFile Path: /Users/kastanday/Zotero/storage/4K73IXWE/Liu et al. - 2021 - Energy-based Out-of-distribution Detection.pdf\\nFull Citation: Liu, Weitang, Xiaoyun Wang, John D. Owens, and Yixuan Li. \\u201cEnergy-Based Out-of-Distribution Detection.\\u201d ArXiv:2010.03759 [Cs], April 26, 2021. http://arxiv.org/abs/2010.03759.\\nIn-Text Citation: (Liu et al., 2021)\\nItem Type: Journal Article\\nTags: Computer Science - Artificial Intelligence, Computer Science - Machine Learning, random online, test-tag-notion\\nTitle: Energy-based Out-of-distribution Detection\\nURL: http://arxiv.org/abs/2010.03759\\nYear: 2021\\nZotero URI: http://zotero.org/users/3570394/items/2NC9P3JQ\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 5,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"Zero\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": -72.172,\n",
       "      \"text\": \"Zero\\nCreated: January 7, 2022 8:46 PM\\nFinished?: No\\n1. Is nature continuous or discrete? Is it infinite or a set size? Remains a question today. \\nBabalonian Base-60 \\nIndian, base 10\\n- should be Indian numerals instead of Arabic.\\nOrigins of the word Zero \\nThe very word zero smacks of its Hindu and Arabic roots. When the Arabs adopted Hindu-Arabic numerals, they also adopted zero. The Indian name for zero was sunya, meaning \\\"empty,\\\" which the Arabs turned into sifr. When some Western scholars described the new number to their colleagues, they turned sir into a Latin-sounding word, yielding zephirus, which is the root of our word zero. Other Western mathematicians didn't change the word so heavily and called zero cifra, which became cipher. Zero was so important to the new set of numbers that people started calling all numbers ciphers, which gave the French their term chiffre, digit.\\nHave to reject old wise ppl \\nIndian mathematicians had made quite clear, zero was the embodiment of the void. Thus, if the Muslims were to accept zero, they had to reject Aristotle. That was precisely what they did.\\n## 4. The Infinite God of Nothing (Theology of Zero)\\nZero and infinity were at the very center of the Renaissance. As Europe slowly awakened from the Dark Ages, the void and the infinitenothing and everything would destroy the Aristotelian foundation of the church and open the way to the scientific revolution.\\nPeople couldn\\u2019t draw realistic paintings until they had a vanishing point (they just had grotesque 2d things). Transformed the art world. \\nin 1515: heliocentric vs geocentric. \\n\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 6,\n",
       "      \"metadata\": {\n",
       "        \"date_created\": null,\n",
       "        \"date_modified\": null,\n",
       "        \"title\": \"(Cui et al., 2016)\\n\"\n",
       "      },\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 124.742,\n",
       "      \"text\": \"(Cui et al., 2016)\\nAbstract: The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory is recently proposed as a theoretical framework for sequence learning in the cortex. In this paper, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable-order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods: autoregressive integrated moving average (ARIMA), feedforward neural networks: online sequential extreme learning machine (ELM), and recurrent neural networks: long short-term memory (LSTM) and echo-state networks (ESN), on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyper- parameters tuning. Therefore the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem, but is also applicable to a wide range of real-world problems such as discrete and continuous sequence prediction, anomaly detection, and sequence classification.\\nAuthors: Cui, Yuwei\\nAhmad, Subutai\\nHawkins, Jeff\\nDOI: https://doi.org/10.1162/NECO_a_00893\\nFile Path: /Users/kastanday/Zotero/storage/GQX4R3XL/Cui et al. - 2016 - Continuous online sequence learning with an unsupe.pdf\\nFull Citation: Cui, Yuwei, Subutai Ahmad, and Jeff Hawkins. \\u201cContinuous Online Sequence Learning with an Unsupervised Neural Network Model.\\u201d Neural Computation 28, no. 11 (November 2016): 2474\\u20132504. https://doi.org/10.1162/NECO_a_00893.\\nIn-Text Citation: (Cui et al., 2016)\\nItem Type: Journal Article\\nTags: Computer Science - Neural and Evolutionary Computing, Quantitative\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"discrete stat distribution\", \n",
    "    max_rerank=7,\n",
    "    file=\"file-NdM8EkdPCKFmEcL9ksaKR27K\",\n",
    "    return_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x16bc9fd30> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 556.838,\n",
       "      \"text\": \"Quantum Mechanics (Big topic)\\n[Andy Matuschak (Tools for Thought)](https://www.notion.so/Andy-Matuschak-Tools-for-Thought-7a44975cec684aa6a797df2e852bc79d) \\nNeumonic medium\\n[Topics](Quantum%20Me%205294f/Topics%20893cc.csv)\\n# Best reading materials out there!!!\\nQuanta Magazine \\u2014 great mag, great videos. \\nWolframphysics.org\\n\\u2b50 [David Deutch's Video Series Introducing Quantum Computation!!!!!](http://www.quiprocone.org/Protected/DD_lectures.htm)\\n- WoW these videos are more than just math. They're theory and beauty of the multiverse.\\n- [All his other resources](https://www.daviddeutsch.org.uk/videos/) (nice!)\\nDifferent rules of probability from what we\\u2019re used to. \\nMath is the distilled heart of thinking. Chains of logic useful for anything. \\nFrom the Map of Physics Youtuber. \\n\\u2b50\\u2b50 [https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum Field Theory for the Gifted Amateur-Oxford University Press (2014).pdf](https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum%20Field%20Theory%20for%20the%20Gifted%20Amateur-Oxford%20University%20Press%20%282014%29.pdf)\\n\\u2b50\\u2b50 [https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf](https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf)\\n\\u2b50\\u2b50 [https://www.damtp.cam.ac.uk/user/tong/qft.html](https://www.damtp.cam.ac.uk/user/tong/qft.html)\\n# Class\\n[Quantum Fourier Transform](Quantum%20Me%205294f/Quantum%20Fo%205a472.md)\\n# Physical Qbits\\n[\\\"Next generation superconducting qubits for quantum computing\\\" presented by Jens Koch, Northwestern - YouTube](https://www.youtube.com/watch?v=VutpQm1TbKo&ab_channel=IllinoisQuantum)\\nhow Qbits are made IRL. \\nCommon case: Transmons. Used by Goog and IBM. \\n2 capacitors.\\nIt\\u2019s a harmonic oscillator, but it will \\u201cspontaneously relax\\u201d into a base state. \\nQuantum noise\\n- Basically: Qbits couple (ideally weakly) with uncontrolled elements (DOF) of the environment.\\n- Reduces how quantum the bit is == decoherence.\\n# Visualizations\\n[A python library for visualizing any combination of gates](https://github.com/cduck/bloch_sphere)\\n# Quantum Country\\n# Quantum Computing for the Very Curious (part 1)\\nI try to remember the number refers to the bottom position. Two computational basis states 0 and 1. \\nBloch sphere\\nSum of probabilities must be 1 (unitary operations)\\nThe Hadamard gate. \\n- splitting up into high-dimensional space, then collecting that back down to a final measurement.\\n- Fanning out, running compu\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 602.312,\n",
       "      \"text\": \"Quantum Fourier Transform\\n[Untitled](Quantum%20Fo%205a472/Untitled.mp4)\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 470.859,\n",
       "      \"text\": \"Quantum Eraser (Delayed Choice)\\nCreated: October 31, 2021 4:34 PM\\n# The bomb experiment\\nTo watch from that one female quantum youtuber \\n# Quantum Eraser (Debunked!!)\\nIt's actually not weird at all.\\nI've been lied to about the double slit!! It's NOT A CLEAN SEPARATION. \\nJust a FUZZIER interference pattern. They go thru one slit at a time, but somehow they still spread out a lot.\\nBeam splitter: reflects half the photons, lets half thru. \\n\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 688.661,\n",
       "      \"text\": \"When it comes down to it, the most obvious applications of quantum computers seem trivial\\u2014naturally, a computer built of photons will be effective at simulating photons. Quantum computers are no more a cure-all for general computation than soapy water is for black hole physics, but this apparent triviality clarifies our challenge.\\n[]()\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 521.848,\n",
       "      \"text\": \"Quantum Physics\\nThere's the standard model, then there's the FULL LIST of all ALL the particles in the Standard model.\\nStandard model: \\n- Left side (3 columns) is mass particles; makes up the matter\\n- Right side: mediate how matter particles interact with each other. They're force carriers.\\n- What sets them apart is SPIN!\\nFull List: \\n- Includes the color charges.\\nField interactions\\nApplication of quantum computing: Material Science. Explore the enormous search space of atom combinations to get good properties.\\n# Part 1 here\\n[If You Don't Understand Quantum Physics, Try This!](https://www.youtube.com/watch?v=Usu9xZfabPM&ab_channel=DoS-DomainofScience)\\n# Part 2: The Interpretations\\n[The Interpretations of Quantum Mechanics](https://www.youtube.com/watch?v=mqofuYCz9gs&ab_channel=DoS-DomainofScience)\\nNotes\\n## 1. The Copenhagen Interpretation \\u2014 standard way of teaching in school.\\nSubatomic particles \\u2014 all obey Wave Function (described by Schrodinger eq)\\nGives us a lot of properties:\\nJust ONE intrepretation](Quantum%20Ph%201540b/Untitled%207.png)\\nThe results of this \\u2190 \\nJust ONE intrepretation\\nThe wave function is a probability distribution. (we can never see the wave function, only the particles when it collapses down into a specific place)\\n# 2. The Many World Interpretation\\nEvery time a particle hits a detector, it splits into many worlds. Every possible observation creates a new branch. \\nBut probability is now meaningless \\u2014 every universe has a 100% probability. Everything always happens (somewhere). What do \\n# 3. Non-Locality (Spooky action at a distance)\\nEntanglement. \\n1. Entangle electrons to have equal and opposite spins\\n1. QUESTION: How do you entangle something, or know if it is entangled? \\n2. Move them far apart\\n1. The same wave function describes both particles\\n3. When you measure 1, the other is collapsed the same. \\nMEANING: One particle's properties is determined by A DIFFERENT PARTICLE. Non-localized dependence.\\nThat's super weird. Only place physics is Non-local.\\n# 4. Hidden Variable Theories\\nThe particles are ALWAYS in a specific state.. we just can't tell until we measure. \\n## Bell's Theorem \\u2014 A testable hypothesis disproving HVT^\\nLocal Hidden variable theories DISPROVEN. \\nBUT Hidden Variables at a distance are possible (apparently....)\\nBecause Bell's Theorem is BUILT on the AXIOM of LOCALITY. \\n# 5. Alternative Collapse Theories\\nFocus on the collapse of the wave (upon measurement) \\nDescribe EXACTLY HOW the wave collapses. \\n- Actually makes a test\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"quantum\", \n",
    "    max_rerank=5,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x16ba5e1b0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 198.224,\n",
       "      \"text\": \"AI Hackathon (Argon National Labs)\\nReach out for Compute resources login, remote access.\\nTom Gibbs Nvidia\\n```python\\nssh kastan@kastan@theta.alcf.anl.gov\\npass: login number off of Pass+ iphone app. \\n```\\nSlack: [AI_Hackathon](https://app.slack.com/client/T02SPS0932P/C02S9FRCAR5) \\nProj description: [AI_Hackathon_Molecular_Dynamics.pdf - Google Drive](https://drive.google.com/file/d/1ipGkyj2O1cE_XFp5lWIoY8JpFCrPmLld/view)\\nMaking teams: [Teams_Hackathon - Google Docs](https://docs.google.com/document/d/12V1oq3kakSCmjAdyEHSZdwQq1qhDVNfCadiGHYRLaTo/edit)\\nGPU docs: [Getting Started on ThetaGPU | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/support-center/theta-gpu-nodes/getting-started-thetagpu)\\nTheta GPU Node trainings:  [Theta GPU Nodes | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/support-center/theta-gpu-nodes)\\nTraining series: [ALCF AI for Science Training Series | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/alcf-ai-science-training-series)\\n- Distributed training on January 27, 2022 [Distributed Training | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/events/distributed-training)\\n- Each session occurs on Thursdays from 3-5 p.m. US CT. Webinars are recorded and posted shortly after each event.\\n## Meetings\\n[First team meeting](AI%20Hackath%20ccc8f/First%20team%20438a7.md)\\n[Project Description (AI hackathon)](AI%20Hackath%20ccc8f/Project%20De%20bb1f6.md)\\n[Benchmarking](AI%20Hackath%20ccc8f/Benchmarki%20a0d51.md)\\n[AI Hackathon Final presentation](AI%20Hackath%20ccc8f/AI%20Hackath%206939d.md)\\n# Webinar training\\n[webinar traning](AI%20Hackath%20ccc8f/webinar%20tr%20458dd.md)\\nReservation from 5-9pm every day. \\nDATA IS HERE: `/lus/grand/projects/AIHacks/first_challenge`\\n```python\\n/lus/grand/projects/AIHacks/first_challenge\\n```\\n## Getting started\\n1. Do dev on compute nodes. \\n2. Log into theta. \\n3. Switch over to ThetaGPU to submit jobs\\n- ^^ If you need public internet access\\n- [2020 ALCF Simulation, Data, and Learning Workshop | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/events/2020-alcf-simulation-data-and-learning-workshop)\\n- https://github.com/argonne-lcf/sdl_ai_workshop\\nProfile perf. on your code.\\nAdding python path (edit .soft.cooley)\\nDO THIS ONE\\nThreads across nodes: \\n# Things\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 156.294,\n",
       "      \"text\": \"Quantum Mechanics (Big topic)\\n[Andy Matuschak (Tools for Thought)](https://www.notion.so/Andy-Matuschak-Tools-for-Thought-7a44975cec684aa6a797df2e852bc79d) \\nNeumonic medium\\n[Topics](Quantum%20Me%205294f/Topics%20893cc.csv)\\n# Best reading materials out there!!!\\nQuanta Magazine \\u2014 great mag, great videos. \\nWolframphysics.org\\n\\u2b50 [David Deutch's Video Series Introducing Quantum Computation!!!!!](http://www.quiprocone.org/Protected/DD_lectures.htm)\\n- WoW these videos are more than just math. They're theory and beauty of the multiverse.\\n- [All his other resources](https://www.daviddeutsch.org.uk/videos/) (nice!)\\nDifferent rules of probability from what we\\u2019re used to. \\nMath is the distilled heart of thinking. Chains of logic useful for anything. \\nFrom the Map of Physics Youtuber. \\n\\u2b50\\u2b50 [https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum Field Theory for the Gifted Amateur-Oxford University Press (2014).pdf](https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum%20Field%20Theory%20for%20the%20Gifted%20Amateur-Oxford%20University%20Press%20%282014%29.pdf)\\n\\u2b50\\u2b50 [https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf](https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf)\\n\\u2b50\\u2b50 [https://www.damtp.cam.ac.uk/user/tong/qft.html](https://www.damtp.cam.ac.uk/user/tong/qft.html)\\n# Class\\n[Quantum Fourier Transform](Quantum%20Me%205294f/Quantum%20Fo%205a472.md)\\n# Physical Qbits\\n[\\\"Next generation superconducting qubits for quantum computing\\\" presented by Jens Koch, Northwestern - YouTube](https://www.youtube.com/watch?v=VutpQm1TbKo&ab_channel=IllinoisQuantum)\\nhow Qbits are made IRL. \\nCommon case: Transmons. Used by Goog and IBM. \\n2 capacitors.\\nIt\\u2019s a harmonic oscillator, but it will \\u201cspontaneously relax\\u201d into a base state. \\nQuantum noise\\n- Basically: Qbits couple (ideally weakly) with uncontrolled elements (DOF) of the environment.\\n- Reduces how quantum the bit is == decoherence.\\n# Visualizations\\n[A python library for visualizing any combination of gates](https://github.com/cduck/bloch_sphere)\\n# Quantum Country\\n# Quantum Computing for the Very Curious (part 1)\\nI try to remember the number refers to the bottom position. Two computational basis states 0 and 1. \\nBloch sphere\\nSum of probabilities must be 1 (unitary operations)\\nThe Hadamard gate. \\n- splitting up into high-dimensional space, then collecting that back down to a final measurement.\\n- Fanning out, running compu\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 174.434,\n",
       "      \"text\": \"Second Call for Proposals Digital Transformation and AI for Energy and Climate Security - C3.ai Digital Transformation Institute\\nThe C3.ai Digital Transformation Institute (C3DTI) was established in March 2020 by C3 AI and Microsoft and co-led by the University of California, Berkeley (UC Berkeley) and the University of Illinois at Urbana-Champaign (UIUC), with consortium partners Carnegie Mellon University, KTH Royal Institute of Technology, Lawrence Berkeley National Laboratory (LBNL), Massachusetts Institute of Technology, Princeton University, Stanford University, and University of Chicago, and with high-performance computing support from LBL and the National Center for Supercomputing Application (NCSA) at UIUC. The goal of C3DTI is to catalyze cooperative research activities and advances in mathematical, statistical, and computing research, combining machine learning (ML), artificial intelligence (AI), the internet of things (IoT) and ethics and social responsibility in the development and fielding of technology. C3DTI is aimed at establishing the fundamental set of scientific advances, algorithms, designs, and business change management practices necessary to establish the Science of Digital Transformation of Societal Systems.\\nC3DTI will contribute to the new and emerging field of Digital Transformation Science by leveraging the personnel, laboratory, and research facilities at UC Berkeley, UIUC, and consortium partner institutions to form dynamic teams of the best researchers in the world to advance IoT and AI techniques for industrial, commercial, and public sector applications. This rich ecosystem will help address some of the most complex issues inherent in a massive societal Digital Transformation and build the foundation for a new Science of Digital Transformation.\\nThe energy industry is being digitally transformed by investment at all levels of production, generation, transmission, and distribution: sensors, data analytics, new privacy-aware markets, and usage of smart meters in homes are all part of this transformation. However, the transformation of energy to be resilient to large environmental changes, faults (including maintenance errors), and cyber-attacks is still a work in progress. The early lead of energy operators in embracing digital transformation has enabled those systems to use digital transformation not only to enhance energy efficiency but also to lead the way to a lower-carbon, higher-efficiency economy that will enhance both \"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 99.332,\n",
       "      \"text\": \"webinar traning\\nAll webinar recordings: [ALCF AI for Science Training Series | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/alcf-ai-science-training-series)\\n# ENV\\nPyTorch:\\n- [ ]  \\u2b50\\u2b50\\u00a0TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL [https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#torchvision-object-detection-finetuning-tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#torchvision-object-detection-finetuning-tutorial)\\nTensorflow:\\nObject Detection API with Tensorflow 2 [https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)\\nKeras: (detailed, code it from bottom up) \\nObject Detection with RetinaNet [https://keras.io/examples/vision/retinanet/](https://keras.io/examples/vision/retinanet/)\\n# RNN (and LSTM)\\n\\u2b50\\u00a0[Advanced AI Applications - YouTube](https://www.youtube.com/watch?v=AOB5kEajQtQ&ab_channel=ArgonneLeadershipComputingFacility)\\nKyle Felker. Uses data science on Fusion reactors.\\nRNNs have vanishing/exploding gradient problem. \\nLSTMs address that, but More expensive.\\nLSTM\\nGRU - Gated Recurrent Unit... mostly hurts the accuracy.\\nProblem: instabilities in the evolution of the plasma in fusion reactor.\\nWant to predict instabilities before they happen to improve safety. \\n128ms sub-sequences of time. \\nThe output (bottom cell) does sound the alarm before reactor instability (red line).\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 182.893,\n",
       "      \"text\": \"[Big topic] Web3\\n# RenoDao Cryptofed and Wyoming govt.\\nFiat voating \\u2014 1 person 1 note. \\nBusiness vote is different from consumer. \\nReno Coin - store of value, or exchange.\\n- Velocity up. \\u2190 big question.\\n- Liquidity pool.\\nCoin token and ownership token. \\nWhy Zero inflation?\\n- how?\\nDigitize reno economy\\n- easier to pay utility bills.\\nStimulation \\u2014 \\n- Private chain.. Mutable?? Can\\u2019t be mutable.\\n- Just for citizens of Reno.\\n- 2.5% on holding. Like federal funds rate.\\n- Enterprise get double the interest rate. Just any LLC?\\n- Payment for order flow.\\n- Dividends. and Real-world project funding.\\nChallenges: \\n1. Getting utilities to accept it. They\\u2019re old fuddies. \\n2. Stable coin?\\nRenoDAO. \\nKYC\\n[Team (americancryptofed.org)](https://www.americancryptofed.org/team)\\n[MakerDAO | An Unbiased Global Financial System](https://makerdao.com/en/)\\n- Good governance\\n[Estonia DAO](https://estoniadao.org/#/)\\nEOS \\nCardano DAO \\nVoting rounds \\u2014 startup funding for startups\\n- [Project Catalyst Community Site](https://projectcatalyst.org/)\\nTezos\\n[LinksDAO](https://linksdao.io/)\\n- a golf course, DAO.\\n# Messari.io\\nGood code elegantly communicates your ideas to computers, and spits out products that delight users. Good prose elegantly communicates your ideas to other humans, incepting new ideas into their heads (through memes), and if you're doing it right, converting missionaries to your cause. Nic Carter had the best piece I read this year, On Writing, which probably not coincidentally happens to be the title of the Stephen King book I recommend to all new professional writers. Nic is crypto's best writer.\\nThis isn't an original thought. BitMEX founder Arthur Hayes broke this analogy down in a piece on the flippening debate, where he says \\n1) it's impossible for ETH to be the world's best virtual computer and the world's best money at the same time (I agree), and \\n2) crypto's largest monetary network will likely be bigger than its biggest distributed tech \\\"company\\\" (yes, again).\\n## Sober, market-and-history-driven analysis of web3\\n[Why it\\u2019s too early to get excited about Web3 \\u2013 O\\u2019Reilly (oreilly.com)](https://www.oreilly.com/radar/why-its-too-early-to-get-excited-about-web3/?utm_campaign=mb&utm_medium=newsletter&utm_source=morning_brew)\\nBenefiting small insiders, before crashing the market like in 2009.\\nAn important conclusion of Perez's analysis is that a true technology revolution must be accompanied by the development of substantial new infrastructure.\\n> What is perhaps the cruci\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"distributed computing\", \n",
    "    max_rerank=5,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x15e6cc450> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 152.89,\n",
       "      \"text\": \"webinar traning\\nAll webinar recordings: [ALCF AI for Science Training Series | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/alcf-ai-science-training-series)\\n# ENV\\nPyTorch:\\n- [ ]  \\u2b50\\u2b50\\u00a0TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL [https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#torchvision-object-detection-finetuning-tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html#torchvision-object-detection-finetuning-tutorial)\\nTensorflow:\\nObject Detection API with Tensorflow 2 [https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)\\nKeras: (detailed, code it from bottom up) \\nObject Detection with RetinaNet [https://keras.io/examples/vision/retinanet/](https://keras.io/examples/vision/retinanet/)\\n# RNN (and LSTM)\\n\\u2b50\\u00a0[Advanced AI Applications - YouTube](https://www.youtube.com/watch?v=AOB5kEajQtQ&ab_channel=ArgonneLeadershipComputingFacility)\\nKyle Felker. Uses data science on Fusion reactors.\\nRNNs have vanishing/exploding gradient problem. \\nLSTMs address that, but More expensive.\\nLSTM\\nGRU - Gated Recurrent Unit... mostly hurts the accuracy.\\nProblem: instabilities in the evolution of the plasma in fusion reactor.\\nWant to predict instabilities before they happen to improve safety. \\n128ms sub-sequences of time. \\nThe output (bottom cell) does sound the alarm before reactor instability (red line).\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 187.606,\n",
       "      \"text\": \"AI Hackathon (Argon National Labs)\\nReach out for Compute resources login, remote access.\\nTom Gibbs Nvidia\\n```python\\nssh kastan@kastan@theta.alcf.anl.gov\\npass: login number off of Pass+ iphone app. \\n```\\nSlack: [AI_Hackathon](https://app.slack.com/client/T02SPS0932P/C02S9FRCAR5) \\nProj description: [AI_Hackathon_Molecular_Dynamics.pdf - Google Drive](https://drive.google.com/file/d/1ipGkyj2O1cE_XFp5lWIoY8JpFCrPmLld/view)\\nMaking teams: [Teams_Hackathon - Google Docs](https://docs.google.com/document/d/12V1oq3kakSCmjAdyEHSZdwQq1qhDVNfCadiGHYRLaTo/edit)\\nGPU docs: [Getting Started on ThetaGPU | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/support-center/theta-gpu-nodes/getting-started-thetagpu)\\nTheta GPU Node trainings:  [Theta GPU Nodes | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/support-center/theta-gpu-nodes)\\nTraining series: [ALCF AI for Science Training Series | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/alcf-ai-science-training-series)\\n- Distributed training on January 27, 2022 [Distributed Training | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/events/distributed-training)\\n- Each session occurs on Thursdays from 3-5 p.m. US CT. Webinars are recorded and posted shortly after each event.\\n## Meetings\\n[First team meeting](AI%20Hackath%20ccc8f/First%20team%20438a7.md)\\n[Project Description (AI hackathon)](AI%20Hackath%20ccc8f/Project%20De%20bb1f6.md)\\n[Benchmarking](AI%20Hackath%20ccc8f/Benchmarki%20a0d51.md)\\n[AI Hackathon Final presentation](AI%20Hackath%20ccc8f/AI%20Hackath%206939d.md)\\n# Webinar training\\n[webinar traning](AI%20Hackath%20ccc8f/webinar%20tr%20458dd.md)\\nReservation from 5-9pm every day. \\nDATA IS HERE: `/lus/grand/projects/AIHacks/first_challenge`\\n```python\\n/lus/grand/projects/AIHacks/first_challenge\\n```\\n## Getting started\\n1. Do dev on compute nodes. \\n2. Log into theta. \\n3. Switch over to ThetaGPU to submit jobs\\n- ^^ If you need public internet access\\n- [2020 ALCF Simulation, Data, and Learning Workshop | Argonne Leadership Computing Facility (anl.gov)](https://www.alcf.anl.gov/events/2020-alcf-simulation-data-and-learning-workshop)\\n- https://github.com/argonne-lcf/sdl_ai_workshop\\nProfile perf. on your code.\\nAdding python path (edit .soft.cooley)\\nDO THIS ONE\\nThreads across nodes: \\n# Things\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 254.92,\n",
       "      \"text\": \"Registering for coures\\n[Course Explorer](https://courses.illinois.edu//)\\nSelf-service link \\n[System Login](https://webprod.admin.uillinois.edu/ssa/servlet/SelfServiceLogin?appName=edu.uillinois.aits.SelfServiceLogin&dad=BANPROD1&target=F)\\n[First semester guidance // insturctions](https://cs.illinois.edu/academics/graduate/graduate-forms-advising-resources/new-graduate-student-resources/ms-general)\\nPast coures of Scientific visualization\\nScientific visualization: [https://courses.engr.illinois.edu/cs519/fa2015/index.html](https://courses.engr.illinois.edu/cs519/fa2015/index.html)\\n[MS Degree Program Worksheet.pdf](Registerin%206c8ac/MS_Degree_Program_Worksheet.pdf)\\n[Registerin%206c8ac/MS_Degree_Program_Worksheet%201.pdf](Registerin%206c8ac/MS_Degree_Program_Worksheet%201.pdf)\\nCS 519\\nCS 581 - Alg Genom bio\\nML for Biofinor\\nPrerec: 446 (sic) and concurrent enrol in 466 (sic)\\n\\u2b50\\u2b50 Intro to bioinfor\\n## RESTRICTED!!!?!?!?!?!?\\n```html\\nRestricted to online graduate non-degree, online MCS, \\nonline MSME, online MSCEE, and online MSAE students.\\n```\\nViz class \\u2014 just for Coursera.\\nNatural Language Processing \\u2014 just for professional MSC, which I guess I'm not. \\nWIEIRD PROBLEMS\\n- Level Restriction - Computer Security I. CS 461\\n## Potential:\\n- Intro to Bioinfor\\n- 519 Visualizations\\n- 581: algorithmic genomic biology\\n## SCHEDULING CONFLICTS\\n- CHOSEN: Alg Genomic Biolg 581. Conflict: Applied Parallel Prog ECE 408.\\nCS 511 - Advanced Data Management \\u2014 Only online (scheduling conflict)\\n- CHOSEN: Alg Genomic Biolg 581. Conflict: Computer Security 1.\\n- \\n- Advanced Data management \\u2014 time conflict and online only (**but I CAN REGISTER, conflict with Introduction to Bioinformatics**)\\n- Applied parallel programming (Conflict with Intro to biolog)\\n# More cool ones:\\n- Transfer-learning: 598. CN 72110\\n- 598 courses are all for special topics, good for finding advisor.\\n- PHD Orientation Seminar\\n- 41977\\n# ACUTALLY SIGNED UP FOR\\n**433 computer System Organization (prerec to security) (IN PERSON, Siebel 1404)**\\n- FIRST TO CUT.\\n- CRN: 43363\\n- CS 433\\n- This is like advanced computer architecture.. Looks hard. Grading is all tests (and some problem sets). Lots of assembly language\\n- [http://cwfletcher.net/433sp21.html#:~:text=CS 433%3A Computer System Organization%2C Spring 2021&text=This course teaches advanced computer,architectures%2C domain-specific architectures](http://cwfletcher.net/433sp21.html#:~:text=CS%20433%3A%20Computer%20System%20Organization%2C%20Spring%202021&text=This%20course%20\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 146.407,\n",
       "      \"text\": \"Quantum Mechanics (Big topic)\\n[Andy Matuschak (Tools for Thought)](https://www.notion.so/Andy-Matuschak-Tools-for-Thought-7a44975cec684aa6a797df2e852bc79d) \\nNeumonic medium\\n[Topics](Quantum%20Me%205294f/Topics%20893cc.csv)\\n# Best reading materials out there!!!\\nQuanta Magazine \\u2014 great mag, great videos. \\nWolframphysics.org\\n\\u2b50 [David Deutch's Video Series Introducing Quantum Computation!!!!!](http://www.quiprocone.org/Protected/DD_lectures.htm)\\n- WoW these videos are more than just math. They're theory and beauty of the multiverse.\\n- [All his other resources](https://www.daviddeutsch.org.uk/videos/) (nice!)\\nDifferent rules of probability from what we\\u2019re used to. \\nMath is the distilled heart of thinking. Chains of logic useful for anything. \\nFrom the Map of Physics Youtuber. \\n\\u2b50\\u2b50 [https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum Field Theory for the Gifted Amateur-Oxford University Press (2014).pdf](https://indico.cern.ch/event/957763/contributions/4025879/attachments/2117913/3598224/Quantum%20Field%20Theory%20for%20the%20Gifted%20Amateur-Oxford%20University%20Press%20%282014%29.pdf)\\n\\u2b50\\u2b50 [https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf](https://www-thphys.physics.ox.ac.uk/people/JohnCardy/qft/qftcomplete.pdf)\\n\\u2b50\\u2b50 [https://www.damtp.cam.ac.uk/user/tong/qft.html](https://www.damtp.cam.ac.uk/user/tong/qft.html)\\n# Class\\n[Quantum Fourier Transform](Quantum%20Me%205294f/Quantum%20Fo%205a472.md)\\n# Physical Qbits\\n[\\\"Next generation superconducting qubits for quantum computing\\\" presented by Jens Koch, Northwestern - YouTube](https://www.youtube.com/watch?v=VutpQm1TbKo&ab_channel=IllinoisQuantum)\\nhow Qbits are made IRL. \\nCommon case: Transmons. Used by Goog and IBM. \\n2 capacitors.\\nIt\\u2019s a harmonic oscillator, but it will \\u201cspontaneously relax\\u201d into a base state. \\nQuantum noise\\n- Basically: Qbits couple (ideally weakly) with uncontrolled elements (DOF) of the environment.\\n- Reduces how quantum the bit is == decoherence.\\n# Visualizations\\n[A python library for visualizing any combination of gates](https://github.com/cduck/bloch_sphere)\\n# Quantum Country\\n# Quantum Computing for the Very Curious (part 1)\\nI try to remember the number refers to the bottom position. Two computational basis states 0 and 1. \\nBloch sphere\\nSum of probabilities must be 1 (unitary operations)\\nThe Hadamard gate. \\n- splitting up into high-dimensional space, then collecting that back down to a final measurement.\\n- Fanning out, running compu\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 196.802,\n",
       "      \"text\": \"Second Call for Proposals Digital Transformation and AI for Energy and Climate Security - C3.ai Digital Transformation Institute\\nThe C3.ai Digital Transformation Institute (C3DTI) was established in March 2020 by C3 AI and Microsoft and co-led by the University of California, Berkeley (UC Berkeley) and the University of Illinois at Urbana-Champaign (UIUC), with consortium partners Carnegie Mellon University, KTH Royal Institute of Technology, Lawrence Berkeley National Laboratory (LBNL), Massachusetts Institute of Technology, Princeton University, Stanford University, and University of Chicago, and with high-performance computing support from LBL and the National Center for Supercomputing Application (NCSA) at UIUC. The goal of C3DTI is to catalyze cooperative research activities and advances in mathematical, statistical, and computing research, combining machine learning (ML), artificial intelligence (AI), the internet of things (IoT) and ethics and social responsibility in the development and fielding of technology. C3DTI is aimed at establishing the fundamental set of scientific advances, algorithms, designs, and business change management practices necessary to establish the Science of Digital Transformation of Societal Systems.\\nC3DTI will contribute to the new and emerging field of Digital Transformation Science by leveraging the personnel, laboratory, and research facilities at UC Berkeley, UIUC, and consortium partner institutions to form dynamic teams of the best researchers in the world to advance IoT and AI techniques for industrial, commercial, and public sector applications. This rich ecosystem will help address some of the most complex issues inherent in a massive societal Digital Transformation and build the foundation for a new Science of Digital Transformation.\\nThe energy industry is being digitally transformed by investment at all levels of production, generation, transmission, and distribution: sensors, data analytics, new privacy-aware markets, and usage of smart meters in homes are all part of this transformation. However, the transformation of energy to be resilient to large environmental changes, faults (including maintenance errors), and cyber-attacks is still a work in progress. The early lead of energy operators in embracing digital transformation has enabled those systems to use digital transformation not only to enhance energy efficiency but also to lead the way to a lower-carbon, higher-efficiency economy that will enhance both \"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"advanced computing\", \n",
    "    max_rerank=5,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x16bc04860> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 280.174,\n",
       "      \"text\": \"iPad Apps\\nInteresting iPad apps for creative notes \\n# Reading academic papers\\nReadcube Papers \\u2014 seems lit for cross platform (all devices)... But no handwriting.\\nGoodReader \\u2014 powerful, cloud PDF editing. Has Handriting.\\niOS only.\\n\\u2b50\\u2b50\\u2b50 **PaperShip** \\u2b50\\u2b50 \\u2014 Hard to setup, but synch beautfiully with Zotero (or mendeley??) Excellent annotation. Replaced Goodreader for this person. \\n- HANDWRITING SYNCH WITH MENDENELY OR ZOTERO!! IT'S PERFECT!!!\\n## Ideal Workflow\\nZotero (+ Zotfile) && annotations are extracted into plaintext!\\nOr \\u2665\\u2665 **Papership** \\u2665\\u2665 ****+ Zotero or Mendenely \\nOr Zotero desktop + zotero ipad app and that's it.\\nOr Zotero + Zotfile + any pdf editor (including handwriting). Cuz the PDF file is synched via (any) cloud.\\nTODO: Zotfile on Zotero. Advanced PDF management\\n- Use ZotFile to send and get files from tablet.\\n- Automatically extract annotations when getting PDFs back from tablet.\\n- Liquid Text \\u2014 NOT GOOD.\\nLiquidText - PDF reader that shares notes between mutlipe PDFs (so you can draw connections between all the PDFs within a folder). Nice features worth a look.\\n- Mac, Ios and Windows10\\n- Most innovateive iPad app fo the year\\n- NO BACUP, NO SYNCH. Not Useable.\\n# Other Notetaking\\n- [https://paperpile.com/](https://paperpile.com/) \\u2014 DOPE all in one reference manager (cross platform)\\n- **GoodNotes** (for (hand)writing lectures and notes) - Must Have.\\n- Notability (for scratch work/research ideas/seminar notes). Similar to Goodnotes.\\n- **GoodReader** (for a PDF library that I can sync and annotate)\\n- Dropbox (getting things on and off the iPad)\\n- PDF Expert ?? Reddit dude likes it. And talented dude tried it.\\n- MarginNote 3\\n- Synch is hit or miss.\\n- Geni\\n- Paperpile (ios) manage research papers\\n### researcher: academic journals\\nNice way to brows journals. Open access. \\n- Can find DOI for anything!\\n# Concepts (StuffMadeHere) drawing\\nLooks amazing.\\nVector-based. SVG export\\n### Procreate to do coloring (ideal for any drawing)\\n# Muse\\nInteract with things in a very different way. Digital whiteboard. Ipad Native w pencil. Fluid and natural. \\nMore creative, more free. \\n# Craft\\nTouch, drag and drop. Blocks based app. \\nBasic. But good split screen. \\n**Basic but more native.**\\nVisually stunning. \\n# Journal\\nSpace for each topic. All kinds of media keeping it beautiful. Collecting inspiration. \\nEase of organization. Just get it all in one place. \\nNotability\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 81.962,\n",
       "      \"text\": \"The 80,000 hours project\\n# The 80,000 hours project\\n[Our new guide to doing good with your career](https://80000hours.org/key-ideas/)\\nPromoting welfare over the long term. \\n- Shaping the development of emerging technologies and reducing the risk of global catastrophes.\\n- \\\"Where can *additional people* make the biggest difference.\\n# How to evaluate a job opportunity:\\n[Job jobs](https://www.notion.so/Job-jobs-f00a62d29608416a93c2650c140493be) \\n1. Specialist career capital \\u2014 how much does it advance you towards your top long-term options?\\n2. Transferable career capital and back-up options \\u2014 does it open up other promising options?\\n3. Information value \\u2014 does it let you test out a potentially excellent but uncertain long-term option?\\n4. Personal fit \\u2014 where do you have the highest chances of excelling? (& relative fit if coordinating with a community)\\n5. Immediate impact \\u2014 will it let you contribute to a pressing problem right away?\\n6. Personal priorities \\u2014 does it fit with the rest of your life and risk-tolerance?\\n## Priority paths\\nHighest-priority areas:\\n- [Positively shaping the development of artificial intelligence](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/)\\n- [Global priorities research](https://80000hours.org/problem-profiles/global-priorities-research/)\\n- [Building effective altruism](https://80000hours.org/problem-profiles/promoting-effective-altruism/)\\n- [Reducing global catastrophic biological risks](https://80000hours.org/problem-profiles/global-catastrophic-biological-risks/)\\nSecond-highest-priority areas:\\n- [Improving institutional decision-making](https://80000hours.org/problem-profiles/improving-institutional-decision-making/)\\n- [Nuclear security](https://80000hours.org/problem-profiles/nuclear-security/)\\n- [Climate change (extreme risks)](https://80000hours.org/problem-profiles/climate-change/)\\nOther potentially promising issues: \\n- [Great power conflict](https://80000hours.org/problem-profiles/#reducing-great-power-conflict)\\n- [Global governance](https://80000hours.org/problem-profiles/#improve-global-governance)\\n- [Voting reform](https://80000hours.org/problem-profiles/#voting-reform)\\n- [Improving individual reasoning or cognition](https://80000hours.org/problem-profiles/#improve-individual-reasoning)\\n- [Global public goods](https://80000hours.org/problem-profiles/#public-goods)\\n- [Surveillance](https://80000hours.org/problem-profiles/#surveillance)\\n- [Atomic scale manufacturing](https://80000hours.o\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"excellent researcher\", \n",
    "    max_rerank=5,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x16bc9fe20> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 192.96,\n",
       "      \"text\": \"Curiosity Notes TransformerNet Comparison\\nStudents struggle to pick out salient points (from new material) - must make required learning explicit.\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#4736170261c44ff483342443409a7ab8 \\nParent: duplicate of Designing Better Books\\nStudents struggle to pick out salient points - must make required learning explicit. \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#9b82eae295ee42ffb2c6677ee8f6c43b \\nParent: Meta-Learning\\nScore: 0.93\\nIndexes:  194 426 \\n\\u2023 \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#3707d864b49d4da883b3c60789d267a4\\nParent: Meta-Learning\\n\\u2023 \\u2023 \\nhttps://www.notion.so/b6355cce267e4d3dbc414af9e2449340#289d26ebf77142759575e1fe3f256e04\\nParent: Media for thinking the unthinkable \\nScore: 0.87\\nIndexes:  395 502 \\nBerkeley Graduate School Theory of Learning\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#b5e99b6ab9324913b6ae31cbd7b9d29f\\nParent: duplicate of Designing Better Books\\nBerkeley Grad Learning Theory\\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#155e369896de4b5f925881096f09ffa3\\nParent: Meta-Learning\\nScore: 0.84\\nIndexes:  186 417 \\nMeta-Learning learning about learning. \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#fcb23c3c961a4dba9ce5b765bab477be\\nParent: Meta-Learning\\nLearning about learning\\nhttps://www.notion.so/babd823cb2024a1fa8588354d13f64b2#61ec4cde0ef14128a202a49fb679d89a\\nParent: Theories of Learning (cog sci)\\nScore: 0.76\\nIndexes:  396 575 \\nRepetition and simple mnemonic study techniques can be extremely effective (like flash cards and spaced repetition, see [Anki](https://apps.ankiweb.net/)).\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#55655990fad747018426414b225e98d0\\nParent: duplicate of Designing Better Books\\nRepetition and simple mnemonic study techniques can be extremely effective.\\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#5f6f8c6c83cf45849cc3eda7f64e7327\\nParent: Meta-Learning\\nScore: 0.75\\nIndexes:  190 422 \\nStartup world\\nhttps://www.notion.so/f24a26b57c874887bdce1c9a79105cb3#c0a9578164a84cff9f72def0b9f4fbd6\\nParent: Tools for Thought (Tools for Better Thinking)\\nStartups\\nhttps://www.notion.so/c276c273b6f54428b97cd60f0204d8b3#a933ea292a2e4d1390e13a01a87aa835\\nParent: Inspiration\\nScore: 0.71\\nIndexes:  521 602 \\n\\u26aa Cauliflower avocado\\nhttps://www.notion.so/d1f41130c04740a5a8c45de6a90c7286#09ea23d7361247ae8b2188c6a4cc13c8\\nParent: Cooking // recipes \\nCauliflower tacos\\nhttps://www.notion.so/041b1531c89441c394eb0accabf0c348#5575235bc5c7\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 186.669,\n",
       "      \"text\": \"Meta-Learning\\n[Piotr Wozniak (Supermemo)](https://www.notion.so/Piotr-Wozniak-Supermemo-1481d7de0e484bb8894c43e028ba92c1) \\nMeta-Learning learning about learning. \\n# Effective Learning\\n[SuperMemo.com](https://www.supermemo.com/en/archives1990-2015/articles/20rules)\\nSupport for [Designing Better Books](https://www.notion.so/Designing-Better-Books-d1d6f7dbc3cf4c46a38289e927381d59) \\n> The same material can be learned many times faster if well formulated!\\n> \\nDon't do \\\"it'll be useful someday learning\\\" it's slow. \\nYou want to group your study of something. Or it loses it's value. *Treacherous enticing fallacy.*\\n## Kastan Day's learning philosophy\\n1. Emotional Salience!\\n2. Individual pieces fit into a single coherent structure (laticework!)\\n3. Teaching this way is very hard. It's so much simpler to just list out things to learn, so YMMV. \\n## [Fast.ai](http://fast.ai) learning philosophy\\nWe\\u2019ll be leveraging the best available research on teaching methods to try to fix these problems with technical teaching, including:\\n- Teaching\\u00a0[\\u201cthe whole game\\u201d](https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719/)\\u2013starting off by showing how to use a complete, working, very usable, state of the art deep learning network to solve real world problems, by using simple, expressive tools. And then gradually digging deeper and deeper into understanding how those tools are made, and how the tools that make those tools are made, and so on\\u2026\\n- Always teaching through examples: ensuring that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation\\n- Simplifying as much as possible:\\u00a0[we\\u2019ve spent months](https://www.fast.ai/2016/10/08/overview/)\\u00a0building tools and teaching methods that make previously complex topics very simple\\n- Removing barriers: deep learning has, until now, been a very exclusive game. We\\u2019re breaking it open, and ensuring that everyone can play\\n- \\u2026and many more. I\\u2019ve discussed some of our approaches to teaching in more detail below.\\nFrom Fastbook page 10\\n### Harvard's David perkins (x fastAI)\\n[Education at Bat: Seven Principles for Educators](https://www.gse.harvard.edu/news/uk/09/01/education-bat-seven-principles-educators)\\n[David Perkins](https://www.notion.so/David-Perkins-86018ad330374da4b559b5f3457cf462) \\u2014 FAST AI reps this guy for learning theory.\\n- Play the whole game\\n- Don't just do batting practice, that's 'elementitis'. Play baseball.\\n- Make the game worth playin\\n- \"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 130.528,\n",
       "      \"text\": \"Labs to work at in UIUC\\n[Applications](Labs%20to%20wo%2015e98/Applicatio%2085d18.csv)\\n# Cover Letter\\n[UIUC Labs Cover Letter](Labs%20to%20wo%2015e98/UIUC%20Labs%20%20e96fe.md)\\n### Document and Pattern Recognition Lab\\nDude works at the new AI for molecular discovery institute ($20MM/5 years)\\nLots of math notion, not my favorite subjects to apply AI to.\\n### Swarthmore Grad one (Tim)\\n[Center for Artificial Intelligence Innovation \\u2013 at the National Center for Supercomputing Applications](Labs%20to%20wo%2015e98/Center%20for%20ae478.md)\\n[Employment \\u2013 Innovative Software and Data Analysis](Labs%20to%20wo%2015e98/Employment%20cb76d.md)\\n[Good machine learning and computer vision words](Labs%20to%20wo%2015e98/Good%20machi%20072e9.md)\\n- [x]  Done\\n[Research Areas](https://cs.illinois.edu/research/areas)\\nOne shot learning and fun meta learning paper \\n[Han Zhao](https://cs.illinois.edu/about/people/faculty/hanzhao)\\n**Assistant Professor (Joining Fall 2021)**\\n[hanzhao@illinois.edu](mailto:hanzhao@illinois.edu)\\nCS 598 - Transfer Learning\\nAsk about this course and if he can share any silibus information. \\n[Tandy Warnow](https://cs.illinois.edu/about/people/faculty/warnow)\\n- BIOE 498 - Intro Bioinformatics for BIOE\\n- BIOE 540 - Algorithmic Genomic Biology\\n- BIOE 598 - Algorithmic Genomic Biology\\nTry to take this course! \\n[Jimeng Sun](https://cs.illinois.edu/about/people/faculty/jimeng)\\n## Seeking Position at Sunlab\\n### **I am\\u00a0always\\u00a0looking for gifted and devoted PhD students, postdocs and interns.**\\nCheck out\\u00a0[our job posting](http://api.sunlab.org/static/media/xxQ/Iqp/5dd94484f8552f0001ed2b2d.pdf)\\u00a0Please submit your applications by emailing\\u00a0[sunlab1280@gmail.com](mailto:sunlab1280@gmail.com)\\u00a0with subject \\u201cPostdoc application\\u201d, \\u201cPhD application\\u201d or \\u201cIntern application\\u201d. Please include your CV, one of your paper and answer the following questions in plain text.\\n- What is your favorite paper from SunLab and why?\\n- What topic do you want to work on and why?\\nLots of ai in healthcare buzzwords!\\nSun's research interest is on artificial intelligence (AI) for healthcare: Deep learning for drug discovery, Clinical trial optimization, Computational phenotyping, Clinical predictive modeling, Treatment recommendation, Health monitoring.\\n- CS 498 - Deep Learning for Healthcare\\n- CS 598 - Deep Learning for Healthcare\\n- CSE 6250 Big Data Analytics for Healthcare - thought many years ina row [http://www.sunlab.org/teaching/cse6250/spring2020/](http://www.sunlab.org/teaching/cse6250/spring\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 246.505,\n",
       "      \"text\": \"Good machine learning and computer vision words\\n[]()\\nSpeaking about machine learning or computer vision papers specifically as concrete examples, in your papers you never \\u201cstudy\\u201d or \\u201cinvestigate\\u201d (there are boring, passive, bad words); instead you \\u201cdevelop\\u201d or even better you \\u201cpropose\\u201d. And you don\\u2019t present a \\u201csystem\\u201d or, shudder, a \\u201cpipeline\\u201d; instead, you develop a \\u201cmodel\\u201d. You don\\u2019t learn \\u201cfeatures\\u201d, you learn \\u201crepresentations\\u201d. And god forbid, you never \\u201ccombine\\u201d, \\u201cmodify\\u201d or \\u201cexpand\\u201d. These are incremental, gross terms that will certainly get your paper rejected :).\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 182.857,\n",
       "      \"text\": \"Farnam Street\\n[Timeless Insight for Business and Life](https://fs.blog/)\\nGood books. First is better than 2nd.\\n\\\"Latticework of mental models\\\" [Mental Models (tools for thought)](Mental%20Mod%20f24a2.md) \\n\\\"Experience is key to learning, and reflection is key to making experience stick\\\"\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 5,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": -35.302,\n",
       "      \"text\": \"engineering for change\\n# Sannitation\\n[Sanitation engineering](engineerin%20d0093/Sanitation%205069d.md)\\n# Renewables\\n[Renewable Energy](Renewable%20%20f866b.md) \\n> The fundamental driver of this change is that renewable energy technologies follow ***learning curves,*** which means that with each doubling of the cumulative installed capacity their price declines by the same fraction.\\n> \\n\\ud83c\\udf1f\\ud83c\\udf1f Learning curve = increased capacity, lower price (proportional)\\n# The 80,000 hours project\\n[The 80,000 hours project](engineerin%20d0093/The%2080,000%2041f1d.md)\\n# \\u2b50\\u2b50 Groups doing good work \\u2b50\\u2b50\\nTo answer this, we primarily aim to synthesize research by the [Global Priorities Institute at the University of Oxford](https://globalprioritiesinstitute.org/), the [Future of Humanity Institute](https://www.fhi.ox.ac.uk/), and [The Open Philanthropy Project](https://www.openphilanthropy.org/research/cause-selection), where we have a number of advisers.\\nA B&M Gates foundation site w nice details:\\n[](http://www.impatientoptimists.org/)\\n- **ARPA-E projects!**\\n# Fields of Innovative Technology Solutions (Where can tech actually be useful)\\n[Where/how can tech do good? ](Where%20how%20%207f9b3.md) \\n[Innovative Technology Solutions](https://www.gatesfoundation.org/What-We-Do/Global-Health/Innovative-Technology-Solutions)\\nThese are PhD RESEARCH TYPE THINGS.... Biotech. Bioinformatics.\\n- Developing a low-cost supplement to colostrum\\u2014the antibody-rich fluid that is the first stage of breast milk\\u2014using novel manufacturing platforms\\n- Using computational science to develop small molecules that have antibody-like potency against infectious diseases such as malaria and tuberculosis\\n- Using DNA encoding to introduce protection against viruses such as Zika and HIV\\n- Engineering B-cells\\u2014the immune cells produced in the bone marrow\\u2014to serve as universal donor cells\\n- Using automation and modular components to develop a health care infrastructure that employs sensor technology and **low-cost molecular testing**\\n- Cheaper diagnostics **\\u2b50\\u2b50 seems really cool.**\\n- Using antibody engineering to develop ultra-sensitive, low-cost rapid diagnostic tests for infectious diseases\\nSo far I\\u2019ve seen people working on this problem, but there\\u2019s a lack of talent in the field with PhD qualifications, combined with the ethical mindset + startup hunger for making progress. The problems are sanitation, machine learning for social good, reducing bias in datasets, and making these modern tools accessible to the global sou\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GOOD ONE!!\n",
    "\n",
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"good learning material\", \n",
    "    max_rerank=6,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"ada\", \n",
    "    query=\"good learning material\", \n",
    "    max_rerank=6,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x10f379120> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"document\": 0,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 192.96,\n",
       "      \"text\": \"Curiosity Notes TransformerNet Comparison\\nStudents struggle to pick out salient points (from new material) - must make required learning explicit.\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#4736170261c44ff483342443409a7ab8 \\nParent: duplicate of Designing Better Books\\nStudents struggle to pick out salient points - must make required learning explicit. \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#9b82eae295ee42ffb2c6677ee8f6c43b \\nParent: Meta-Learning\\nScore: 0.93\\nIndexes:  194 426 \\n\\u2023 \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#3707d864b49d4da883b3c60789d267a4\\nParent: Meta-Learning\\n\\u2023 \\u2023 \\nhttps://www.notion.so/b6355cce267e4d3dbc414af9e2449340#289d26ebf77142759575e1fe3f256e04\\nParent: Media for thinking the unthinkable \\nScore: 0.87\\nIndexes:  395 502 \\nBerkeley Graduate School Theory of Learning\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#b5e99b6ab9324913b6ae31cbd7b9d29f\\nParent: duplicate of Designing Better Books\\nBerkeley Grad Learning Theory\\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#155e369896de4b5f925881096f09ffa3\\nParent: Meta-Learning\\nScore: 0.84\\nIndexes:  186 417 \\nMeta-Learning learning about learning. \\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#fcb23c3c961a4dba9ce5b765bab477be\\nParent: Meta-Learning\\nLearning about learning\\nhttps://www.notion.so/babd823cb2024a1fa8588354d13f64b2#61ec4cde0ef14128a202a49fb679d89a\\nParent: Theories of Learning (cog sci)\\nScore: 0.76\\nIndexes:  396 575 \\nRepetition and simple mnemonic study techniques can be extremely effective (like flash cards and spaced repetition, see [Anki](https://apps.ankiweb.net/)).\\nhttps://www.notion.so/8ebc461341ea4d9fb79f2994778625fe#55655990fad747018426414b225e98d0\\nParent: duplicate of Designing Better Books\\nRepetition and simple mnemonic study techniques can be extremely effective.\\nhttps://www.notion.so/b4da244dc6fb487c8ec6b6f64873374e#5f6f8c6c83cf45849cc3eda7f64e7327\\nParent: Meta-Learning\\nScore: 0.75\\nIndexes:  190 422 \\nStartup world\\nhttps://www.notion.so/f24a26b57c874887bdce1c9a79105cb3#c0a9578164a84cff9f72def0b9f4fbd6\\nParent: Tools for Thought (Tools for Better Thinking)\\nStartups\\nhttps://www.notion.so/c276c273b6f54428b97cd60f0204d8b3#a933ea292a2e4d1390e13a01a87aa835\\nParent: Inspiration\\nScore: 0.71\\nIndexes:  521 602 \\n\\u26aa Cauliflower avocado\\nhttps://www.notion.so/d1f41130c04740a5a8c45de6a90c7286#09ea23d7361247ae8b2188c6a4cc13c8\\nParent: Cooking // recipes \\nCauliflower tacos\\nhttps://www.notion.so/041b1531c89441c394eb0accabf0c348#5575235bc5c7\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 1,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 186.669,\n",
       "      \"text\": \"Meta-Learning\\n[Piotr Wozniak (Supermemo)](https://www.notion.so/Piotr-Wozniak-Supermemo-1481d7de0e484bb8894c43e028ba92c1) \\nMeta-Learning learning about learning. \\n# Effective Learning\\n[SuperMemo.com](https://www.supermemo.com/en/archives1990-2015/articles/20rules)\\nSupport for [Designing Better Books](https://www.notion.so/Designing-Better-Books-d1d6f7dbc3cf4c46a38289e927381d59) \\n> The same material can be learned many times faster if well formulated!\\n> \\nDon't do \\\"it'll be useful someday learning\\\" it's slow. \\nYou want to group your study of something. Or it loses it's value. *Treacherous enticing fallacy.*\\n## Kastan Day's learning philosophy\\n1. Emotional Salience!\\n2. Individual pieces fit into a single coherent structure (laticework!)\\n3. Teaching this way is very hard. It's so much simpler to just list out things to learn, so YMMV. \\n## [Fast.ai](http://fast.ai) learning philosophy\\nWe\\u2019ll be leveraging the best available research on teaching methods to try to fix these problems with technical teaching, including:\\n- Teaching\\u00a0[\\u201cthe whole game\\u201d](https://www.amazon.com/Making-Learning-Whole-Principles-Transform/dp/0470633719/)\\u2013starting off by showing how to use a complete, working, very usable, state of the art deep learning network to solve real world problems, by using simple, expressive tools. And then gradually digging deeper and deeper into understanding how those tools are made, and how the tools that make those tools are made, and so on\\u2026\\n- Always teaching through examples: ensuring that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation\\n- Simplifying as much as possible:\\u00a0[we\\u2019ve spent months](https://www.fast.ai/2016/10/08/overview/)\\u00a0building tools and teaching methods that make previously complex topics very simple\\n- Removing barriers: deep learning has, until now, been a very exclusive game. We\\u2019re breaking it open, and ensuring that everyone can play\\n- \\u2026and many more. I\\u2019ve discussed some of our approaches to teaching in more detail below.\\nFrom Fastbook page 10\\n### Harvard's David perkins (x fastAI)\\n[Education at Bat: Seven Principles for Educators](https://www.gse.harvard.edu/news/uk/09/01/education-bat-seven-principles-educators)\\n[David Perkins](https://www.notion.so/David-Perkins-86018ad330374da4b559b5f3457cf462) \\u2014 FAST AI reps this guy for learning theory.\\n- Play the whole game\\n- Don't just do batting practice, that's 'elementitis'. Play baseball.\\n- Make the game worth playin\\n- \"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 2,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 130.528,\n",
       "      \"text\": \"Labs to work at in UIUC\\n[Applications](Labs%20to%20wo%2015e98/Applicatio%2085d18.csv)\\n# Cover Letter\\n[UIUC Labs Cover Letter](Labs%20to%20wo%2015e98/UIUC%20Labs%20%20e96fe.md)\\n### Document and Pattern Recognition Lab\\nDude works at the new AI for molecular discovery institute ($20MM/5 years)\\nLots of math notion, not my favorite subjects to apply AI to.\\n### Swarthmore Grad one (Tim)\\n[Center for Artificial Intelligence Innovation \\u2013 at the National Center for Supercomputing Applications](Labs%20to%20wo%2015e98/Center%20for%20ae478.md)\\n[Employment \\u2013 Innovative Software and Data Analysis](Labs%20to%20wo%2015e98/Employment%20cb76d.md)\\n[Good machine learning and computer vision words](Labs%20to%20wo%2015e98/Good%20machi%20072e9.md)\\n- [x]  Done\\n[Research Areas](https://cs.illinois.edu/research/areas)\\nOne shot learning and fun meta learning paper \\n[Han Zhao](https://cs.illinois.edu/about/people/faculty/hanzhao)\\n**Assistant Professor (Joining Fall 2021)**\\n[hanzhao@illinois.edu](mailto:hanzhao@illinois.edu)\\nCS 598 - Transfer Learning\\nAsk about this course and if he can share any silibus information. \\n[Tandy Warnow](https://cs.illinois.edu/about/people/faculty/warnow)\\n- BIOE 498 - Intro Bioinformatics for BIOE\\n- BIOE 540 - Algorithmic Genomic Biology\\n- BIOE 598 - Algorithmic Genomic Biology\\nTry to take this course! \\n[Jimeng Sun](https://cs.illinois.edu/about/people/faculty/jimeng)\\n## Seeking Position at Sunlab\\n### **I am\\u00a0always\\u00a0looking for gifted and devoted PhD students, postdocs and interns.**\\nCheck out\\u00a0[our job posting](http://api.sunlab.org/static/media/xxQ/Iqp/5dd94484f8552f0001ed2b2d.pdf)\\u00a0Please submit your applications by emailing\\u00a0[sunlab1280@gmail.com](mailto:sunlab1280@gmail.com)\\u00a0with subject \\u201cPostdoc application\\u201d, \\u201cPhD application\\u201d or \\u201cIntern application\\u201d. Please include your CV, one of your paper and answer the following questions in plain text.\\n- What is your favorite paper from SunLab and why?\\n- What topic do you want to work on and why?\\nLots of ai in healthcare buzzwords!\\nSun's research interest is on artificial intelligence (AI) for healthcare: Deep learning for drug discovery, Clinical trial optimization, Computational phenotyping, Clinical predictive modeling, Treatment recommendation, Health monitoring.\\n- CS 498 - Deep Learning for Healthcare\\n- CS 598 - Deep Learning for Healthcare\\n- CSE 6250 Big Data Analytics for Healthcare - thought many years ina row [http://www.sunlab.org/teaching/cse6250/spring2020/](http://www.sunlab.org/teaching/cse6250/spring\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 3,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 246.505,\n",
       "      \"text\": \"Good machine learning and computer vision words\\n[]()\\nSpeaking about machine learning or computer vision papers specifically as concrete examples, in your papers you never \\u201cstudy\\u201d or \\u201cinvestigate\\u201d (there are boring, passive, bad words); instead you \\u201cdevelop\\u201d or even better you \\u201cpropose\\u201d. And you don\\u2019t present a \\u201csystem\\u201d or, shudder, a \\u201cpipeline\\u201d; instead, you develop a \\u201cmodel\\u201d. You don\\u2019t learn \\u201cfeatures\\u201d, you learn \\u201crepresentations\\u201d. And god forbid, you never \\u201ccombine\\u201d, \\u201cmodify\\u201d or \\u201cexpand\\u201d. These are incremental, gross terms that will certainly get your paper rejected :).\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 4,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": 182.857,\n",
       "      \"text\": \"Farnam Street\\n[Timeless Insight for Business and Life](https://fs.blog/)\\nGood books. First is better than 2nd.\\n\\\"Latticework of mental models\\\" [Mental Models (tools for thought)](Mental%20Mod%20f24a2.md) \\n\\\"Experience is key to learning, and reflection is key to making experience stick\\\"\"\n",
       "    },\n",
       "    {\n",
       "      \"document\": 5,\n",
       "      \"object\": \"search_result\",\n",
       "      \"score\": -35.302,\n",
       "      \"text\": \"engineering for change\\n# Sannitation\\n[Sanitation engineering](engineerin%20d0093/Sanitation%205069d.md)\\n# Renewables\\n[Renewable Energy](Renewable%20%20f866b.md) \\n> The fundamental driver of this change is that renewable energy technologies follow ***learning curves,*** which means that with each doubling of the cumulative installed capacity their price declines by the same fraction.\\n> \\n\\ud83c\\udf1f\\ud83c\\udf1f Learning curve = increased capacity, lower price (proportional)\\n# The 80,000 hours project\\n[The 80,000 hours project](engineerin%20d0093/The%2080,000%2041f1d.md)\\n# \\u2b50\\u2b50 Groups doing good work \\u2b50\\u2b50\\nTo answer this, we primarily aim to synthesize research by the [Global Priorities Institute at the University of Oxford](https://globalprioritiesinstitute.org/), the [Future of Humanity Institute](https://www.fhi.ox.ac.uk/), and [The Open Philanthropy Project](https://www.openphilanthropy.org/research/cause-selection), where we have a number of advisers.\\nA B&M Gates foundation site w nice details:\\n[](http://www.impatientoptimists.org/)\\n- **ARPA-E projects!**\\n# Fields of Innovative Technology Solutions (Where can tech actually be useful)\\n[Where/how can tech do good? ](Where%20how%20%207f9b3.md) \\n[Innovative Technology Solutions](https://www.gatesfoundation.org/What-We-Do/Global-Health/Innovative-Technology-Solutions)\\nThese are PhD RESEARCH TYPE THINGS.... Biotech. Bioinformatics.\\n- Developing a low-cost supplement to colostrum\\u2014the antibody-rich fluid that is the first stage of breast milk\\u2014using novel manufacturing platforms\\n- Using computational science to develop small molecules that have antibody-like potency against infectious diseases such as malaria and tuberculosis\\n- Using DNA encoding to introduce protection against viruses such as Zika and HIV\\n- Engineering B-cells\\u2014the immune cells produced in the bone marrow\\u2014to serve as universal donor cells\\n- Using automation and modular components to develop a health care infrastructure that employs sensor technology and **low-cost molecular testing**\\n- Cheaper diagnostics **\\u2b50\\u2b50 seems really cool.**\\n- Using antibody engineering to develop ultra-sensitive, low-cost rapid diagnostic tests for infectious diseases\\nSo far I\\u2019ve seen people working on this problem, but there\\u2019s a lack of talent in the field with PhD qualifications, combined with the ethical mindset + startup hunger for making progress. The problems are sanitation, machine learning for social good, reducing bias in datasets, and making these modern tools accessible to the global sou\"\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"ada:2020-05-03\",\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine(\"ada\").search(\n",
    "    search_model=\"davinci\", \n",
    "    query=\"good learning material\", \n",
    "    max_rerank=6,\n",
    "    file=\"file-YvfHj7utJala3er24T0ZqeLb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4vGlbfU6IukQEYMqSe8a8WiIekSMf at 0x10f3ef010> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" to the problem of a new approach to business\\n\\nThe problem of a new approach to business can be solved by adopting a customer-centric approach. This involves putting the customer at the center of everything\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1649554495,\n",
       "  \"id\": \"cmpl-4vGlbfU6IukQEYMqSe8a8WiIekSMf\",\n",
       "  \"model\": \"text-davinci:002\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# import openai\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.Completion.create(\n",
    "  engine=\"text-davinci-002\",\n",
    "  prompt=\"A winning solution\",\n",
    "  max_tokens=40,\n",
    "  temperature=1.5, # higher = more creative. Deafult: 1.\n",
    "  top_p=0.3, #lower = limiting\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kastanday/code/githubs/openai/openai_embeddings.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kastanday/code/githubs/openai/openai_embeddings.ipynb#ch0000021?line=0'>1</a>\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87879b51d8eadd594c84597a855dbc4bf19bd011091a6c78af18c0324360ea62"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
